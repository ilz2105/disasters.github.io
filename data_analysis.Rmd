---
title: "Statistical Analysis"
output:
  html_document:
    code_folding: hide
---
 
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(rvest)
library(modelr)
library(mgcv)

ave_temp = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tavg.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    mean_temp = mean(value)) %>%
  select(state_code, location, year, mean_temp) %>%
  distinct() %>%
  ungroup()

precip = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-pcp.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    total_precip = sum(value)) %>%
  select(state_code, location, year, total_precip) %>%
  distinct() %>%
  ungroup()

tmax = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmax.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    max_temp = max(value)) %>%
  select(state_code, location, year, max_temp) %>%
  distinct() %>%
  ungroup()

tmin = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmin.csv", skip = 3)  %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    min_temp = min(value)) %>%
  select(state_code, location, year, min_temp) %>%
  distinct() %>%
  ungroup()

disasters = read_csv("./data/DisasterDeclarationsSummaries2.csv") %>%
  janitor::clean_names() %>%
  mutate(disaster = factor(incident_type)) %>%
  rename(
     year = fy_declared) %>%
  filter(year >= 1953 & year <= 2018) %>%
  count(state, year, disaster) %>%
  ungroup()

final_data =
  inner_join(ave_temp, precip, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  inner_join(tmax, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  inner_join(tmin, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  full_join(disasters, by = c("year" = "year", "state_code" = "state")) %>%
  mutate(n = replace_na(n, 0)) %>%
  group_by(year, location) %>%
  mutate(
    n_state = sum(n)
  ) %>%
  group_by(year) %>%
  mutate(
    n_total = sum(n)
  ) %>%
  group_by(year, disaster) %>%
  mutate(
    n_type = sum(n)
  ) %>%
  rename("n_disaster_state" = "n") %>%
  mutate(
  region = case_when(
    location %in% c(
                    "Alabama","Arkansas","Delaware","Florida","Georgia"
                    ,"Kentucky","Louisiana","Maryland","Mississippi",
                    "Oklahoma","North Carolina","South Carolina",
                    "Tennessee","Texas","Virginia","West Virginia") ~ "southeast",
   location %in% c("Connecticut","Maine","New Hampshire","Massachusetts",
                   "New Jersey","New York","Pennsylvania","Rhode Island","Vermont") ~ 'northeast',
  location %in% c("Alaska",
                "Arizona","California","Colorado","Hawaii","Idaho",
                "Montana","Nevada","New Mexico","Oregon","Utah","Washington","Wyoming")
       ~  'west',
  location %in% c("Illinois",
                "Indiana","Iowa","Kansas","Michigan","Missouri",
                "Minnesota","Nebraska","North Dakota","Ohio","South Dakota", "Wisconsin") ~ 'midwest'))
 
regional_data = final_data %>%
  group_by(year, region) %>%
  mutate(
    ave_temp = mean(mean_temp),
    sum_precip = sum(total_precip),
    count_region = sum(n_disaster_state)
  ) %>%
  select(region, year, ave_temp, sum_precip, count_region) %>%
  filter(region != "NA") %>%
  distinct() %>%
  ungroup()
```
 
### Hypothesis
Has the US seen more natural disasters over time? Our team hypothesizes that the continental United States is seeing an increase in count of natural disasters over the years as average temperatures rise. We will consider including average temperature, total precipitation, and year in our model.

### Distribution of Outcome: Count of Disasters
```{r poisson_dist, echo = FALSE, warning = FALSE, message = FALSE}
poisson_dist = regional_data %>%
  select(year, count_region) %>%
  distinct() %>%
  ggplot(aes(x = count_region)) +
  geom_density(alpha = .5) +
  theme(legend.position = "none") +
  labs(
    x = "Count of Disasters")
poisson_dist
```

### Modeling: Poisson vs Negative Binomial Regression
After inspecting the summary visualizations and plotting the distribution of the data, we decided to run a Poisson regression model to formally test the hypothesis that the count of natural disasters by US region is increasing between 1953-2018. The distribution illustrating the number of disasters per year indicated that our data was highly right skewed. Poisson modeling is appropriate because (1) we are modeling count data and (2) our data is right skewed with positive values only. Motivated by our exploratory visualizations, we also decided it was necessary to control for mean temperature and precipitation.

There are two main ways to model this data:   

  (1) **Poisson Regression**: assumes mean = variance  
  
  (2) **Negative Binomial Regression**: accounts for overdispersion where variance > mean  
  

#### Variables of Interest  
First, let's consider our variables of interest. 

+ **Count of Disasters:** The number of disasters by year and region.
 
+ **Year:** Ranges from 1953 to 2018.
 
+ **Region:** The US regions categorized by Midwest (reference category), Northeast, Southwest, and West. These regions were defined by the [World Atlas definitions](https://www.worldatlas.com/articles/the-regions-of-the-united-states.html).
 
+ **Average Temperture:** The average temperature in degrees Fahrenheit by region.
 
+ **Precipitation:** The total amount of rainfall in inches by region.

#### Cross Validation

After testing various models with just Poisson, we fit a final model that takes the form: 

$$ log(\lambda Count \ of \ Disasters) = \beta_0 + \beta_1 Year + \beta_2 Region + \beta_3 Average \ temp + \beta_4 Precipitation $$

Now we can use cross validation to test whether Poisson or Negative Binomial Regression fits our data best. 

```{r cross_validation, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)

poisson_model = glm(count_region ~ year + region + ave_temp + sum_precip, 
                    family = "poisson"(link = "log"), data = regional_data)

neg_binomial_model = glm.nb(count_region ~ year + region + ave_temp + sum_precip, 
                            data = regional_data)

count_cv = 
  crossv_mc(regional_data, 100)

count_cv = 
  count_cv %>% 
  mutate(  
    model_poisson = map(train, ~glm(count_region ~ year + region + ave_temp + sum_precip,
                                    family="poisson" (link = log), data=regional_data)), 
    model_neg_binomial = map(train, ~ glm.nb(count_region ~ year + region + ave_temp + sum_precip, 
                                             data=regional_data))) %>% 
  mutate(rmse_poisson = map2_dbl(model_poisson, test, ~rmse(model = .x, data = .y)), 
         rmse_negative_binomial = map2_dbl(model_neg_binomial, test, ~rmse(model = .x, data = .y)))

count_cv %>% 
  dplyr::select(rmse_poisson, rmse_negative_binomial) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "Prediction Error Distributions"
  )

```

Reviewing the distributions of residual mean squared errors above, it is hard to distinguish between our two models. Instead, we can compare AICs and use the model with the lowest AIC. 

**Poisson Model**

```{r poisson_aic, echo = FALSE, warning = FALSE, message = FALSE}
poisson_model %>%
  broom::glance() %>% 
  dplyr::select(AIC) %>% 
  knitr::kable(digits = 3)
```


**Negative Binomial Model**
```{r nb_aic, echo = FALSE, warning = FALSE, message = FALSE}
neg_binomial_model %>% 
  broom::glance() %>% 
  dplyr::select(AIC) %>% 
  knitr::kable(digits = 3)
```

Using AIC as a measure for Goodness of Fit, we choose the Poisson Model. 

```{r}
poisson_output = poisson_model %>%
  broom::tidy() %>%
  dplyr::select(term, estimate, p.value) %>%
  mutate(exp(estimate)) 

poisson_output %>% 
  knitr::kable(digits = 3)
```


### Main Findings
Fitting the Poisson regression model, the results were significant at the 5% level of significance. After adjusting for region in the US, average temperature, and precipitation, we found that for every increase in year, the count of natural disastrs increase by  `r poisson_output %>% filter(term == "year") %>% pull("exp(estimate)") %>% round(digits = 3)`. Similarly, we found that as compared to the Midwest region of the United States, the Northeast, Southeast, and West regions saw an increase in the number of natural disasters during our specified time period. This supported our hypothesis that the count of natural disasters increased from 1953 to 2018. 

However, we also found that average temperature is negatively associated with count of natural disasters. We expected that the gradual increase in temperature per year would be associated with count of natural disasters. Reflecting on this, we can conclude that the varying types of natural disasters (earthquake, severe storms, etc) may not be associated with temperature. 

### Limitations
There are several large limitations to this analysis:   

* **Year**: We assumed a linear relationship with the continuous variable Year (1953-2018) and log of expected count of natural disasters. This is most likely not correct and further research must consider how to best use a time related variable.   

* **Missing Data**: NOAA did not have climate indicator variables for the states of Hawaii and Alaska.   

* **Other Variablaes**: Our team considered only a subset of possible climate indicator variables. Futher researchers should consider how else to represent climate change. 

