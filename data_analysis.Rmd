---
title: "Statistical Analysis"
output:
  html_document:
    code_folding: hide
---
 
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(rvest)
ave_temp = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tavg.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    mean_temp = mean(value)) %>%
  select(state_code, location, year, mean_temp) %>%
  distinct() %>%
  ungroup()
precip = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-pcp.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    total_precip = sum(value)) %>%
  select(state_code, location, year, total_precip) %>%
  distinct() %>%
  ungroup()
tmax = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmax.csv", skip = 3) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    max_temp = max(value)) %>%
  select(state_code, location, year, max_temp) %>%
  distinct() %>%
  ungroup()
tmin = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmin.csv", skip = 3)  %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month"), sep = 4) %>%
mutate(
    year = as.numeric(year),
    state_code = setNames(state.abb, state.name)[location]) %>%
  filter(year >= 1953 & year <= 2018) %>%
  group_by(location, year) %>%
  mutate(
    min_temp = min(value)) %>%
  select(state_code, location, year, min_temp) %>%
  distinct() %>%
  ungroup()
disasters = read_csv("./data/DisasterDeclarationsSummaries2.csv") %>%
  janitor::clean_names() %>%
  mutate(disaster = factor(incident_type)) %>%
  rename(
     year = fy_declared) %>%
  filter(year >= 1953 & year <= 2018) %>%
  count(state, year, disaster) %>%
  ungroup()
final_data =
  inner_join(ave_temp, precip, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  inner_join(tmax, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  inner_join(tmin, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>%
  full_join(disasters, by = c("year" = "year", "state_code" = "state")) %>%
  mutate(n = replace_na(n, 0)) %>%
  group_by(year, location) %>%
  mutate(
    n_state = sum(n)
  ) %>%
  group_by(year) %>%
  mutate(
    n_total = sum(n)
  ) %>%
  group_by(year, disaster) %>%
  mutate(
    n_type = sum(n)
  ) %>%
  rename("n_disaster_state" = "n") %>%
  mutate(
  region = case_when(
    location %in% c(
                    "Alabama","Arkansas","Delaware","Florida","Georgia"
                    ,"Kentucky","Louisiana","Maryland","Mississippi",
                    "Oklahoma","North Carolina","South Carolina",
                    "Tennessee","Texas","Virginia","West Virginia") ~ "southeast",
   location %in% c("Connecticut","Maine","New Hampshire","Massachusetts",
                   "New Jersey","New York","Pennsylvania","Rhode Island","Vermont") ~ 'northeast',
  location %in% c("Alaska",
                "Arizona","California","Colorado","Hawaii","Idaho",
                "Montana","Nevada","New Mexico","Oregon","Utah","Washington","Wyoming")
       ~  'west',
  location %in% c("Illinois",
                "Indiana","Iowa","Kansas","Michigan","Missouri",
                "Minnesota","Nebraska","North Dakota","Ohio","South Dakota", "Wisconsin") ~ 'midwest'))
 
regional_data = final_data %>%
  group_by(year, region) %>%
  mutate(
    ave_temp = mean(mean_temp),
    sum_precip = sum(total_precip),
    count_region = sum(n_disaster_state)
  ) %>%
  select(region, year, ave_temp, sum_precip, count_region) %>%
  filter(region != "NA") %>%
  distinct() %>%
  ungroup()
```
 
### Hypothesis: 
Has the US seen more natural disasters over time? Our team hypotehsizes that the continental United States is seeing an increase in count of natural disasters over the years as average temperatures rise. We will consider including temperature varibles, total precipitation (inches), and year in our model.

### Distribution of Outcome: Count of Disasters
```{r poisson_dist, echo = FALSE, warning = FALSE, message = FALSE}
poisson_dist = regional_data %>%
  select(year, count_region) %>%
  distinct() %>%
  ggplot(aes(x = count_region)) +
  geom_density(alpha = .5) +
  theme(legend.position = "none") +
  labs(
    x = "Count of Disasters")
poisson_dist
```

### Modeling: Poisson Regression
After inspecting the summary visualizations and plotting the distribution of the data, we decided to run a Poisson regression model to formally test the hypothesis that the count of natural disasters by US region has increased from 1953 to 2018. The distribution illustrating the number of disasters per year indicated that our data was highly right skewed. Poisson modeling is appropriate because (1) count data is usually right skewed and (2) linear regression modeling can produce negative predictive values which is not appropriate for count data. Motivated by our exploratory visualizations, we also decided it was necessary to control for mean temperature and precipitation.
 
+ **Count of Disasters:** The number of disasters by year and region.
 
+ **Year:** Ranges from 1953 to 2018.
 
+ **Region:** The US regions categorized by Midwest (reference category), Northeast, Southwest, and West. These regions were defined by the [World Atlas definitions](https://www.worldatlas.com/articles/the-regions-of-the-united-states.html).
 
+ **Average Temperture:** The average temperature in degrees Fahrenheit by region.
 
+ **Precipitation:** The total amount of rainfall in inches by region.
 
We fit a Poisson regression where our final model took the form:
$$ log(\lambda Count \ of \ Disasters) = \beta_0 + \beta_1 Year + \beta_2 Region + \beta_3 Average \ temp + \beta_4 Precipitation $$

```{r poisson_model, echo = FALSE, warning = FALSE, message = FALSE}
poisson_model = glm(count_region ~ year + region + ave_temp + sum_precip, family="poisson" (link = log), data=regional_data)

poisson_model %>%
  broom::tidy() %>%
  select(term, estimate, p.value) %>%
  mutate(exp(estimate)) %>% 
  knitr::kable(digits = 3)
```

### Main Findings
Fitting the Poisson regression model, the results were significant at the 5% level of significance. After adjusting for region in the US, average temperature, and precipitation, we found that for every increase in year, there was a 1.034 increase of natural disasters by US region. Similarly, we found that as compared to the Midwest region of the United States, the Northeast, Southeast, and West regions had seen increases in the number of natural disasters during our specified time period. This supported our hypothesis that the count of natural disasters increased from 1953 to 2018.



```{r}
library(modelr)
library(mgcv)
library(MASS)
library(tidyverse)

neg_binomial_model = glm.nb(count_region ~ year + region + ave_temp + sum_precip, data = regional_data)

count_cv = 
  crossv_mc(regional_data, 100) 

count_cv = 
  count_cv %>% 
  mutate(  
    model_poisson = map(train, ~glm(count_region ~ year + region + ave_temp + sum_precip,
                                    family="poisson" (link = log), data=regional_data)), 
    model_neg_binomial = map(train, ~ glm.nb(count_region ~ year + region + ave_temp + sum_precip,
                               data=regional_data))) %>% 
  mutate(rmse_poisson = map2_dbl(model_poisson, test, ~rmse(model = .x, data = .y)), 
         rmse_negative_binomial = map2_dbl(model_neg_binomial, test, ~rmse(model = .x, data = .y)))

count_cv = 
  count_cv %>% 
  mutate(  
    model_poisson = map(train, ~glm(count_region ~ year + region + ave_temp + sum_precip,
                                    family="poisson" (link = log), data=regional_data))) %>% 
  mutate(rmse_poisson = map2_dbl(model_poisson, test, ~rmse(model = .x, data = .y)))

count_cv %>% 
  select(rmse_poisson) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "Prediction Error Distributions Between Models"
  )
```