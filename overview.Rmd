---
title: "Project Report"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    code_folding: hide
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(rvest)
```

# Motivation
According to the United States Geological Survey, scientists predict that increasing global surface temperatures will increase the frequency of droughts and intensity of storms globally. Recent studies examining sea-level rise patterns and projections (Hauer, 2017; Kulp & Strauss, 2019) have suggested that sea-level rise could induce large-scale migration in the United States away from unprotected coastlines and towards inland areas, redistributing population density across the country. The potential impacts of climate change are far-reaching, ranging from human migration and displacement to increased pressure on inland areas and land disturbance. We are interested in examining if there is an association between indicators of climate change (temperature and precipitation) and the frequency of natural disasters in the United States since 1953.

# Related Work
Oddly enough, the initial inspiration for this work actually came from the coveted p8105 Cow Sticker. Our original project idea was going to revolve around cows but our discussions of cows quickly shifted to methane gas and the effects it has on our planet. As a result, we pivoted to examining climate change and natural disasters. Additionally, our work with NOAA data in class, seeing first hand how in-depth that dataset is, gave us an early understanding of the possibilities achievable with such varied data. 

In the news, climate change has been a hot topic of conversation, particularly surrounding increasing global temperatures and increased intensity of natural disasters. We have seen setbacks and progress made recently. Under the Trump Administration, the United States will pull out of the Paris Agreement as of November 4, 2020. Our group personally discussed the implications of this policy and we voiced our concerns while discussing project idases. However, there are people out there doing fantastic work in the fight for our planet, and we hope to do our part. Recently, Greta Thunberg visited NYC for the Climate Strike on September 20, 2019. An estimated 60,000 people participated in NYC while millions joined globally. We are inspired by this action by young people and hope it motivates others to join the cause. We hope our findings can do just a small part in this movement. And maybe get a sticker with a cow on it if we get a little creative along the way.

# Initial Questions
We first want to know if the total count of natural disasters are increasing every five years between 1953-2018 in the United States. We also want to know if average, minimum, and maximum land temperatures are increasing with certain natural disasters over time, examining the states where the frequency of natural disasters does significantly increase with temperature in greater detail. We will fit a multivariable regression model to address our question of whether the United States overall is seeing more natural disasters over time, then create multiple data visualizations to assess state-by-state differences.

# Data Source
Our team used a publicly available dataset called the ["Disaster Declarations Summary"](https://www.fema.gov/media-library/assets/documents/28318) (Version 2) from the Federal Emergency Management Agency (FEMA). This dataset contains summary level data on disaster declarations from 1953 to March 2019 by state and includes all three types of disaster declarations: major disaster, emergency, and fire 
management assistance. 

For the climate change indicators, we will use publicly available data from the National Oceanic and Atmospheric Administration (NOAA). We will pull data on average, maximum and minimum temperature and total precipitation by month by state from 1895. These values came from [NOAA's Climate at a Glance](https://www.ncdc.noaa.gov/cag/national/mapping/) data.

## Data Cleaning
```{r disasters, echo = FALSE, warning = FALSE, message = FALSE}
# clean and pull natural disasters by state and year
# 1) imported downloaded data
# 2) updated variable types and names
# 3) selected variables of interest 
disasters = read_csv("./data/DisasterDeclarationsSummaries2.csv") %>% 
  janitor::clean_names() %>% 
  mutate(disaster = factor(incident_type)) %>% 
  rename(
     year = fy_declared) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  count(state, year, disaster) %>%
  group_by(year, state) %>% 
  mutate(
    n_state = sum(n)
  ) %>% 
  group_by(year) %>% 
  mutate(
    n_total = sum(n)
  ) %>% 
  group_by(year, disaster) %>% 
  mutate(
    n_type = sum(n)
  ) %>% 
  rename("n_disaster_state" = "n") 
```
* **Disaster Declarations Summary**: This data set was downloaded as a .csv file and imported into R. After cleaning the variable names and converting appropriate variables to factors, we renamed several variables and kept information on `State`, `Disaster Year` and `Disaster Type`. Then, we counted disasters by year, state, and type. Overall, there were `r disasters %>% nrow()` disasters delared to FEMA. 

* **Climate Indicators**: These data sets were downloaded from NOAA's website directly. Data on average temperature, minimum temperature, maximum temperature, and total precipitation were recorded for year month by State since 1853. After pulling the data and cleaning variable names, the date fields were split into "Month" and "Year". Next, data were grouped by state and year and summarized as described below:

```{r ave_temp, echo = FALSE, warning = FALSE, message = FALSE}
# clean and pull average temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took average temperature across state by year
# 5) selected variables of interest and distinct rows
ave_temp = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tavg.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    mean_temp = mean(value)) %>% 
  select(state_code, location, year, mean_temp) %>% 
  distinct()
```
  + **Average Temperature** The average temperature by state across all 12 months per year was summarized. 
  

```{r tmin, echo = FALSE, warning = FALSE, message = FALSE}
# clean and pull minimum temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took minimum temperature across state by year
# 5) selected variables of interest and distinct rows
tmin = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmin.csv", skip = 3)  %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    min_temp = min(value)) %>% 
  select(state_code, location, year, min_temp) %>% 
  distinct()
```
  + **Minimum Temperature**: The minimum temperature by state across all 12 months per year was summarized. 
  
```{r tmax, echo = FALSE, warning = FALSE, message = FALSE}
# clean and pull maximum temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took maximum temperature across state by year
# 5) selected variables of interest and distinct rows
tmax = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmax.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    max_temp = max(value)) %>% 
  select(state_code, location, year, max_temp) %>% 
  distinct()
```
  + **Maximum Temperature**: The maximum temperature by state across all 12 months per year was summarized. 
  
```{r precip, echo = FALSE, warning = FALSE, message = FALSE}
# clean and pull precipitation by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) summed total precipitation across state by year
# 5) selected variables of interest and distinct rows
precip = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-pcp.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    total_precip = sum(value)) %>% 
  select(state_code, location, year, total_precip) %>% 
  distinct()
```
  + **Total Precipitation**: The total precipation by state across all 12 months per year was totaled. 


## Final Data Set
```{r joined, echo = FALSE, warning = FALSE, message = FALSE}
# joined data from 5 data sets
final_data = 
  inner_join(ave_temp, precip, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  inner_join(tmax, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  inner_join(tmin, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  full_join(disasters, by = c("year" = "year", "state_code" = "state"))
```
Data on climate change indicators across 4 data sets were inner joined by `State` and `Year`. This created a data set with average temperature, maximum temperature, minimum temperature, and total precipitation by state and year from 1853-2018. Then, this data set was full joined to the disaster data set which had rows for each disaster by Year and State. 


## Data Challenges
There were a couple data challenges along the way. First, our climate data had full state names ("New York") while our disaster data had FIP code and state abbreviations ("NY"). The data was joined after converting the full state name to state codes in the climate data. Additionally, we did have a major issue with data availability. From 11/25/2019-12/2/2019, the NOAA data was unavailable due to scheduled maintenance. Because we pulled all of our climate data directly from the NOAA website, we were unable to work on this final project for 5 days. While this created some last minute stress, it did not ultimately affect our work product.  

# Exploratory Analysis

# Additional Analysis 
Cows!!

# Discussion




Contributors: Holly Finertie | Matt Curran | Jana Lee | Ashley Tseng | Lulu Zhang