---
title: "Project Report"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    code_folding: hide
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(rvest)
```

# Motivation
According to the United States Geological Survey, scientists predict that increasing global surface temperatures will increase the frequency of droughts and intensity of storms globally. Recent studies examining sea-level rise patterns and projections ([Hauer, 2017](https://www.nature.com/articles/nclimate3271); [Kulp & Strauss, 2019](https://www.nature.com/articles/s41467-019-12808-z)) have suggested that sea-level rise could induce large-scale migration in the United States away from unprotected coastlines and towards inland areas, redistributing population density across the country. The potential impacts of climate change are far-reaching, ranging from human migration and displacement to increased pressure on inland areas and land disturbance.


<center>
<img src="data/climate.png" style="width:60%">
</center> 
  
  


# Related Work
Oddly enough, the initial inspiration for this work actually came from the coveted p8105 Cow Sticker. Our original project idea was going to revolve around cows but our discussions of cows quickly shifted to methane gas and the effects it has on our planet. As a result, we pivoted to examining climate change and natural disasters. Additionally, our work with NOAA data in class, seeing first hand how in-depth that dataset is, gave us an early understanding of the possibilities achievable with such varied data. 

In the news, climate change has been a hot topic of conversation, particularly surrounding increasing global temperatures and increased intensity of natural disasters. We have seen setbacks and progress made recently. Under the Trump Administration, the United States will pull out of the [Paris Agreement](https://www.washingtonpost.com/climate-environment/2019/11/04/trump-makes-it-official-us-will-withdraw-paris-climate-accord/) as of November 4, 2020. Our group personally discussed the implications of this policy and we voiced our concerns while discussing project ideas. However, there are people out there doing fantastic work in the fight for our planet, and we hope to do our part. Recently, Greta Thunberg visited NYC for the [Climate Strike](https://www.outsideonline.com/2402494/new-york-city-climate-march) on September 20, 2019. An estimated 60,000 people participated in NYC while millions joined globally. We are inspired by this action by young people and hope it motivates others to join the cause. We hope our findings can do just a small part in this movement. And maybe get a sticker with a cow on it if we get [a little creative](secret_cow.html) along the way.

# Initial Questions
We first want to know if the total count of natural disasters are increasing every five years between 1953-2018 in the United States. We also want to know if average, minimum, and maximum land temperatures are increasing with certain natural disasters over time, examining the states where the frequency of natural disasters does significantly increase with temperature in greater detail. We will fit a multivariable Poisson regression model to address our question of whether the United States overall is seeing more natural disasters over time, then create multiple data visualizations to assess state-by-state differences.

# Data Source
Our team used a publicly available dataset called the ["Disaster Declarations Summary"](https://www.fema.gov/media-library/assets/documents/28318) (Version 2) from the Federal Emergency Management Agency (FEMA). This dataset contains summary level data on disaster declarations from 1953 to March 2019 by state and includes all three types of disaster declarations: major disaster, emergency, and fire management assistance. 

For the climate change indicators, we will use publicly available data from the National Oceanic and Atmospheric Administration (NOAA). We will pull data on average, maximum and minimum temperature, and total precipitation by month by state from 1895. These values came from [NOAA's Climate at a Glance](https://www.ncdc.noaa.gov/cag/national/mapping/) data.

## Data Cleaning
```{r disasters,  warning = FALSE, message = FALSE}
disasters = read_csv("./data/DisasterDeclarationsSummaries2.csv") %>% 
  janitor::clean_names() %>% 
  mutate(disaster = factor(incident_type)) %>% 
  rename(
     year = fy_declared) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  count(state, year, disaster) %>%
  group_by(year, state) %>% 
  mutate(
    n_state = sum(n)) %>% 
  group_by(year) %>% 
  mutate(
    n_total = sum(n)) %>% 
  group_by(year, disaster) %>% 
  mutate(
    n_type = sum(n)) %>% 
  rename("n_disaster_state" = "n") 
```
**Disaster Declarations Summary**: This dataset was downloaded as a .csv file and imported into R. After cleaning the variable names and converting appropriate variables to factors, we renamed several variables and kept information on state, disaster year, and disaster type. Then, we counted disasters by year, state, and type. 

```{r climate, warning = FALSE, message = FALSE}
ave_temp = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tavg.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    mean_temp = mean(value)) %>% 
  dplyr::select(state_code, location, year, mean_temp) %>% 
  distinct() %>% 
  ungroup()

tmin = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmin.csv", skip = 3)  %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    min_temp = min(value)) %>% 
  dplyr::select(state_code, location, year, min_temp) %>% 
  distinct() %>% 
  ungroup()

tmax = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmax.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    max_temp = max(value)) %>% 
  dplyr::select(state_code, location, year, max_temp) %>% 
  distinct() %>% 
  ungroup()

precip = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-pcp.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
 mutate(
    year = as.numeric(year), 
    state_code = setNames(state.abb, state.name)[location]) %>% 
  filter(year >= 1953 & year <= 2018) %>% 
  group_by(location, year) %>% 
  mutate(
    total_precip = sum(value)) %>% 
  dplyr::select(state_code, location, year, total_precip) %>% 
  distinct() %>% 
  ungroup()
```

* **Climate Indicators**: These datasets were downloaded from NOAA's website directly. Data on average temperature, minimum temperature, maximum temperature, and total precipitation were recorded monthly by state since 1953. After pulling the data and cleaning variable names, the date fields were split into month and year. Next, data were grouped by state and year and summarized as described below:
  
  + **Average Temperature** The average temperature, in degrees Fahrenheit, by state across all 12 months per year was summarized. 
  
  + **Minimum Temperature**: The minimum temperature, in degrees Fahrenheit, by state across all 12 months per year was summarized. 
  
  + **Maximum Temperature**: The maximum temperature, in degrees Fahrenheit, by state across all 12 months per year was summarized. 
  
  + **Total Precipitation**: The total precipation, in inches, by state across all 12 months per year was totaled. 

## Final Dataset
```{r joined, warning = FALSE, message = FALSE}
final_data = 
  inner_join(ave_temp, precip, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  inner_join(tmax, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  inner_join(tmin, by = c("location" = "location", "year" = "year", "state_code" = "state_code")) %>% 
  full_join(disasters, by = c("year" = "year", "state_code" = "state"))
```
Data on climate change indicators across four datasets were inner-joined by state and year. This created a dataset with average temperature, maximum temperature, minimum temperature, and total precipitation by state and year. Then, this dataset was full-joined to the disaster dataset which had rows for each disaster by year and state.


## Data Challenges
There were a couple data challenges along the way. First, our climate data had full state names ("New York") while our disaster data had FIPS codes and state abbreviations ("NY"). The data was joined after converting the full state name to state codes in the climate data. Additionally, we did have a major issue with data availability. From 11/25/2019-12/1/2019, the NOAA data was unavailable due to scheduled maintenance. Because we pulled all of our climate data directly from the NOAA website, we were unable to work on this final project for the entire Thanksgiving break. While this created some last minute stress, it did not ultimately affect our work product.  

# Exploratory Analysis

[Climate Indicators](insert link)

[Natural Disasters](https://ashleytseng.shinyapps.io/shiny_dashboard/)

[Interactive Map](https://mrc2229.shinyapps.io/shiny_map/)

# Summary Visualizations

Plots [were generated](summary_viz.html) to look at trends by region for disasters, average temperature, and total precipitation from 1953 to 2018. Specific regions had greater numbers of certain disasters. Overall, the number of disasters increased from 1953 to 2018. 

# Statistical Analysis

### Justification for Poisson Regression
After inspecting the summary visualizations and plotting the distribution of the data, we decided to run a [Poisson regression model](data_analysis.html) to formally test the hypothesis that the count of natural disasters by US region has increased from 1953 to 2018. The distribution illustrating the number of disasters per year indicated that our data was not normally distributed. Rather, our data followed a Poisson distribution, thereby justifying a Poisson model with disaster count data. Motivated by our exploratory visualizations, we also decided it was necessary to control for average temperature and precipitation.

### Main Findings
Fitting the Poisson regression model, the results were significant at the 5% level of significance. After adjusting for region in the US, average temperature, and precipitation, we found that for every increase in year, there was a 1.034 increase of natural disasters by US region. Similarly, we found that as compared to the Midwestern region of the United States, the Northeastern, Southeastern, and Western regions had seen increases in the number of natural disasters during our specified time period. This supported our hypothesis that the count of natural disasters has increased from 1953 to 2018.

# Discussion




Contributors: Holly Finertie | Matt Curran | Jana Lee | Ashley Tseng | Lulu Zhang