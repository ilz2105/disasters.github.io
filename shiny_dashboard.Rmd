---
title: "Shiny Dashboard"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
runtime: shiny
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(viridis)
library(plotly)
library(rvest)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


```{r loadtidydata, echo = FALSE, results = 'hide', message = FALSE}
# clean and pull average temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took average temperature across state by year
# 5) selected variables of interest and distinct rows
ave_temp = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tavg.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    fips_state_code = as.numeric(location_id)) %>% 
  filter(year >= 1953 & year != 2019) %>% 
  group_by(location, year) %>% 
  mutate(
    mean_temp = mean(value)) %>% 
  select(fips_state_code, location, year, mean_temp) %>% 
  distinct()

# clean and pull precipitation by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) summed total precipitation across state by year
# 5) selected variables of interest and distinct rows
precip = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-pcp.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    fips_state_code = as.numeric(location_id)) %>% 
  filter(year >= 1953 & year != 2019) %>% 
  group_by(location, year) %>% 
  mutate(
    total_precip = sum(value)) %>% 
  select(fips_state_code, location, year, total_precip) %>% 
  distinct()

# clean and pull maximum temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took maximum temperature across state by year
# 5) selected variables of interest and distinct rows
tmax = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmax.csv", skip = 3) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    fips_state_code = as.numeric(location_id)) %>% 
  filter(year >= 1953 & year != 2019) %>% 
  group_by(location, year) %>% 
  mutate(
    max_temp = max(value)) %>% 
  select(fips_state_code, location, year, max_temp) %>% 
  distinct()

# clean and pull minimum temperature by state and month. 
# 1) pulled data from online
# 2) created year and month fields
# 3) grouped by state and year
# 4) took minimum temperature across state by year
# 5) selected variables of interest and distinct rows
tmin = read_csv("https://www.ncdc.noaa.gov/cag/statewide/mapping/110-tmin.csv", skip = 3)  %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month"), sep = 4) %>%
  mutate(
    year = as.numeric(year), 
    fips_state_code = as.numeric(location_id)) %>% 
  filter(year >= 1953 & year != 2019) %>% 
  group_by(location, year) %>% 
  mutate(
    min_temp = min(value)) %>% 
  select(fips_state_code, location, year, min_temp) %>% 
  distinct()

# clean and pull natural disasters by state and year
# 1) imported downloaded data
# 2) updated variable types and names
# 3) selected variables of interest 
disasters = read_csv("./data/DisasterDeclarationsSummaries2.csv") %>% 
  janitor::clean_names() %>% 
  mutate(incident_type = factor(incident_type), 
       fips_state_code = fips_state_code*100) %>% 
  rename(
     year = fy_declared, 
     disaster = incident_type) %>% 
  select(fips_state_code, year, disaster)

# joined data from 5 data sets
final_data = 
  inner_join(ave_temp, precip, by = c("location" = "location", "year" = "year", "fips_state_code" = "fips_state_code")) %>% 
  inner_join(tmax, by = c("location" = "location", "year" = "year", "fips_state_code" = "fips_state_code")) %>% 
  inner_join(tmin, by = c("location" = "location", "year" = "year", "fips_state_code" = "fips_state_code")) %>% 
  full_join(disasters, by = c("year" = "year", "fips_state_code" = "fips_state_code")) %>% 
  rename(state = location)
```


Column {.sidebar}
-----------------------------------------------------------------------

```{r echo = FALSE}
state_name = 
  final_data %>% 
  filter(state != "NA") %>% 
  distinct(state) %>% 
  pull(state)

selectInput(
  "state_choice", 
  label = h3("Select State"),
  choices = state_name, selected = "Alabama")



disaster_name = 
  final_data %>% 
  filter(disaster != "NA") %>% 
  distinct(disaster)

selectInput(
  "disaster_choice", 
  label = h3("Select Disaster Type"),
  choices = disaster_name, selected = "Coastal Storm")
```

Column {data-width=650}
-----------------------------------------------------------------------

### Number of Disasters Over Time

```{r, echo = FALSE}
renderPlotly({
  final_data %>% 
    filter(
      state == input[["state_choice"]], 
      disaster == input[["disaster_choice"]]) %>%
    count(state, disaster) %>% 
    mutate(disaster = fct_reorder(disaster, n)) %>% 
    rename(
      "Total Number of Disaster Events" = "n",
      "Year" = "year") %>% 
    plot_ly(x = ~Year, y = ~`Total Number of Disaster Events`, color = ~disaster, type = "bar")
})
```

Column {data-width=350}
-----------------------------------------------------------------------

### Chart B

```{r, echo = FALSE}

```

### Chart C

```{r, echo = FALSE}

```

